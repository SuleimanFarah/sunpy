# Organization:  SunPy in OpenAstronomy

### Project: Developing SunKit Image
##### Mentors: @Cadair, @wafels, @Nabobalis

## CURRENTLY UPDATED VERSION IS IN DOCS. WILL UPDATE THIS

#### Student Information


* **Name**: Prateek Chanda
* **Time Zone** : +05:30 GMT
* **IRC Handle** : prateekiiest
* **Github ID**: [prateekiiest](https://github.com/prateekiiest)
* **Blog**  - [Prateek Chanda @Medium](medium.com/@prateekkol21)
* **LinkedIn** : [My LinkedIn Profile](https://www.linkedin.com/in/prateek-chanda-iiest/)
* **Website** : [CodeFolio](https://prateekiiest.github.io)
*  **Mail** :  prateekkol21@gmail.com or  prateek.dd2015@cs.iiests.ac.in
--------------

#### University Information



*     University: Indian Institute of Engineering Science and Technology, Shibpur
*        Major: Computer Science and Engineering
*        Current Academic Year : Third Year
*       Graduate Year: 2019

---------

#### Experience In Programming


* I have been involved in open source for the past 2 years and been contributing to different open source projects including Algorithms based and Python based Desktop Applications.
*  Intermediate knowledge of Python for Data Science and Statistical Analysis.
*   I have contributed to some projects on Algorithms. Hence I am comfortable in working with Git and using GitHub.
*   An active coder on [HackerRank](https://www.hackerrank.com/prateekkol2103) and [HackerEarth](https://www.hackerearth.com/@prateekkol21/).
*   I am comfortable in doing programs in Python. I did two major projects on Machine Learning in Python which majorly  uses statistical analysis (pandas, numpy) and the use of Jupyter Notebook. These were  project works for Udacity Machine Learning Nanodegree:
 -  [Titanic Survival Exploration](https://github.com/prateekiiest/titanic_survival_exploration)
 -  [Boston Housing](https://github.com/prateekiiest/boston_housing)
* I worked recently on one of my personal projects based in python which saw many active participation from different communities. The project being called [Code Sleep Python](https://github.com/prateekiiest/Code-Sleep-Python). It is a project
based in python for building desktop applications and games in python.
* I did one research internship previous year on machine learning at CNERG research Lab, IIT Kharagpur where I worked on a data mining project using Python.


#### Hackathons and Open Source experience

* Go-Hack Idea 2016:  I participated in Go-Hack Idea in 2016 where I proposed an idea on smart home security systems along with some small implementations using Adruino, Raspberry Pi.
* Contributing to Organizations like FOSSASIA and other small organisations: I had been contributing to some open source organizations and repositories for the past two years.
I  have currently total 163 Pull Requests done so far and 72 issues being worked so far.
* Currently I have around 93 repository projects and among them 75 repositories (some big and some small projects) are the ones that I have contributed to. All my contributions can be seen on my [github profile](https://github.com/prateekiiest).
* Mentored students under different Open Source events like Hacktoberfest , Kharagpur Winter of Code and 24 Pull Requests on some of my own personal projects primarily written in Python.
* Got the opportunity to speak at different Open Source Summits. Got invited to different developer conferences like RISE Hong Kong 2017, FOSSASIA Open Tech , Google Developers Solve for India among others.
* Currently I am the GitHub Campus Expert of my college and along with direct support from GitHub I am helping to grow my community in campus, involving more people in Open Source and coding.


---------------


#### Interest In OpenAstronomy

OpenAstronomy consisting of 8 sub-organisations is a collaboration between open source astronomy and astrophysics projects that are being used by researchers around the world to study our universe. The analysis of data obtained from observatories like SDO , Hubble Space Telescope helps multiple types of research from being able to forecast a solar storm to detect planets in other stars.

**Astronomy is at the frontier of science.** There are new discoveries made all the time.

I had always a love for the sky and a kind of childhood fascination in the field astronomy and to me its feels amazing to see real time data of the Sun , captured just a few hours back, in my computer screen and I am able to analyse those data obtained.
The organisation is inspiring new developers like me to join the open source community and build the project code base together with lead developers and that is where I find the joy of Open Source.
It has been really a great experience contributing to Sunpy since I joined the Sunpy community.

I did not qualify for my first GSOC with Open Astronomy back in 2017. But I did not give up. I loved the project and wanted to contribute as much as I can. Having been worked with the SunPy project for the past 1 year, I learnt many new things in open source, team management, writing long lines of code and lastly the joy of your contribution being accepted.

OpenAstronomy along with Google Summer of Code will give me this opportunity to be a part of these huge project work on Solar Data Analysis and I feel it as a privilege to contribute to such an open-source software in the field of astronomy.


###  Contribution to Sunpy

I have been involved with the SunPy project for the past 1 year contributing since December 2016. And I am delighted to be a part of consecutive 7 version releases of SunPy and am grateful to being
acknowledged for my work.

| Pull Requests |  Corresponding Issue | Status |
|:-------------:|:-------------:|:-------------:|
|[More Mapcubes Examples - Gallery Examples #2455](https://github.com/sunpy/sunpy/pull/2455)| [More examples in the gallery on simple map and mapcube manipulation #2413](https://github.com/sunpy/sunpy/issues/2413) | Open |
| [ImageAnimatorWCS Update #2306](https://github.com/sunpy/sunpy/pull/2306)|[Ticklabel Control for ImageAnimatorWCS #2288](https://github.com/sunpy/sunpy/issues/2288) | Open |
|[Remove Gamma usage in Map #2424](https://github.com/sunpy/sunpy/pull/2424)|[Gamma in map doesn't do anything #2333](https://github.com/sunpy/sunpy/issues/2333)|Merged|
|[Finding Local Peaks in Solar Data - Gallery Update #2339](https://github.com/sunpy/sunpy/pull/2339 )| Suggested this example| Merged|
|[Masking Hot Pixels](https://github.com/sunpy/sunpy/pull/2325)| Found Bug in Example| Merged|
|[Brightest pixel location may occur at multiple position](https://github.com/sunpy/sunpy/pull/2319)|Found similar bug in Example| Merged |
|[Brightest pixel location redundancy removed](https://github.com/sunpy/sunpy/pull/2318)|Removed Redundancy in Examples | Merged|
|[differential_rotation.py rot_hpc to use sunpy.coordinates](https://github.com/sunpy/sunpy/pull/2107)|Enhancement from my side| Closed|
|[Added documentation for suds-py3 incompatibility](https://github.com/sunpy/sunpy/pull/2073)| [VSOClient.query returns no result in Python 3.5](https://github.com/sunpy/sunpy/issues/1912)|Merged|
|[Create north_offset_frame.py Gallery Example Added](https://github.com/sunpy/sunpy/pull/2066)|Gallery Example| Closed|
|[Update README.md Matrix Org linked](https://github.com/sunpy/sunpy/pull/2059)|Enhancement | Merged |
|[Update README.md](https://github.com/sunpy/sunpy/pull/2054)|[README badges broken](https://github.com/sunpy/sunpy/issues/2053)|Merged|
|[suds-py3 does not work with VSO added documentation](https://github.com/sunpy/sunpy/pull/2052)|[VSOClient.query returns no result in Python 3.5](https://github.com/sunpy/sunpy/issues/1912)|Closed|
|[Added documentation for database/tests](https://github.com/sunpy/sunpy/pull/2049)|[database tests depend on data/tests dir](https://github.com/sunpy/sunpy/issues/732)|Merged|
|[Update vso.py](https://github.com/sunpy/sunpy/pull/2042)|Enhancement Documentation |Merged|
|[Update spectrogram.py](https://github.com/sunpy/sunpy/pull/2034)|Enhancement, updating class formats|Closed|
|[Update test_time.py ](https://github.com/sunpy/sunpy/pull/2030)| Enhancement tests| Closed|
|[Update time.py Removed extract_time](https://github.com/sunpy/sunpy/pull/2029)|[Remove extract_time function](https://github.com/sunpy/sunpy/issues/2024)|Merged|
|[Update rescale.py](https://github.com/sunpy/sunpy/pull/2022)|[reshape_image_to_4d_superpixel array seems broken](https://github.com/sunpy/sunpy/issues/2020)|Merged|
|[Updated tests for resampling Generic Map and some documentation in the Sunpy/data/test](https://github.com/sunpy/sunpy/pull/2011) and [Update dimensions metadata](https://github.com/sunpy/sunpy/pull/2010) |[Update dimensions metadata when resampling a map](https://github.com/sunpy/sunpy/issues/1870)|Closed|
|[show_colormaps() should check how much display is available Update cm.py ](https://github.com/sunpy/sunpy/pull/1980)|Enhancement on improving colormaps display| Closed|
|[net.vso.attrs broken in RST fixed](https://github.com/sunpy/sunpy/pull/2300)|[Some docstrings for net.vso.attrs are not showing up correctly on RTD](https://github.com/sunpy/sunpy/issues/2299)| Closed|


Contribution to SunPy Website

| Pull Requests |  Corresponding Issue | Status |
|:-------------:|:-------------:|:-------------:|
|[help section Docs link updated](https://github.com/sunpy/sunpy.github.io/pull/92)|[Sunpy Documentation Link Showing Privacy Error](https://github.com/sunpy/sunpy.github.io/issues/91)| Merged |
|[Sunpy Presentations and Talks Upload on the Site](https://github.com/sunpy/sunpy.github.io/pull/90)|Enhancement|Merged|
|[Registry of Sunpy Affiliated Packages](https://github.com/sunpy/sunpy.github.io/pull/89)|Enhancement -Introducing Affiliated Packages Registry |Merged|
|[Author attributes update](https://github.com/sunpy/sunpy.github.io/pull/77) and [Author names link to github under blog posts](https://github.com/sunpy/sunpy.github.io/pull/74)|Enhancement for Blogging System|Closed|
|[Update bootstrap.css bootstrap version updated](https://github.com/sunpy/sunpy.github.io/pull/72)|[Update bootstrap](https://github.com/sunpy/sunpy.github.io/issues/39)|Merged|
|[Update about.html Community Link updated to matrix](https://github.com/sunpy/sunpy.github.io/pull/71)|Enhancement| Merged|
|[Update contribute.html link updated to matrix channel](https://github.com/sunpy/sunpy.github.io/pull/68)|Enhancement|Merged|
|[Update help.html Link updated to matrix ](https://github.com/sunpy/sunpy.github.io/pull/65)|Enhancement|Merged|


| Issues Opened
|:--------------:|
| [reshape_image_to_4d_superpixel array seems broken : #2020](https://github.com/sunpy/sunpy/issues/2020)
| [AttributeError for BufferedIOBase while running python setup.py build_docs -o : #2031](https://github.com/sunpy/sunpy/issues/2031)
|[Spectrogram Attributes not Documented Well #2033](https://github.com/sunpy/sunpy/issues/2033)
| [README badges broken #2053](https://github.com/sunpy/sunpy/issues/2053)
|[ Code not showing up in maps.rst for plotting keywords and colormap section #2046](https://github.com/sunpy/sunpy/issues/2046)
|[Possible Bug in MapcubeAnimator updatefig method](https://github.com/sunpy/sunpy/issues/2444)

------------


### Abstract

This project aims at building the foundations of the `sunkit-image`which is  a SunPy affiliated package. This package will be built specifically for image processing routines related to solar data analysis. Through this package SunPy users can analyze solar images  collected from different solar data observatories and get a clear picture of image processing applications in the field of solar physics.

The package will contain some of the most well-known image processing algorithms structured in a well manner readily usable package. By implementing all such algorithms in a single package will not only give the user the freedom to analyze solar plots with simplicity by simply calling the modules but also not let them bother about the underlying complexity of the implementation.

### Project Goals

As part of the project there are major 4 milestones that need to be completed as part of the GSOC project. Also I plan to work on only one optional extra if time permits as per the timeline.

* Implement the normalizing-radial-graded filter (NRGF).
* Porting the Multi-Scale Gaussian Normalisation - MGN code in the package repository.
* Implementation of the OCCULT-2 Algorithm for coronal loop tracing.
* Implement image re-sampling

### Detailed Description

The project involves majorly four parts along with optional extras. A detailed analysis of each part of the project is described as follows

#### Implementation of the Normal-Radial-Graded Filter(NRGF)

The very sharp decrease of density with heliocentric distance makes imaging of coronal density structures out to a few solar radii challenging.
The radial gradient in brightness can be reduced using numerous image processing techniques like NRGF.
Normalizing radial graded filter (NRGF) is thus a simple filter for removing the radial gradient to reveal coronal structure.
It presents a robust normalization technique. The main idea behind this technique can be given by the following equation.

![](https://user-images.githubusercontent.com/1392107/36587049-2bb7c5da-1884-11e8-8aba-f94fae35d64f.png)

where the Intensity of the Image is represented in polar coordinates.

**What needs to be done**

 The IDL version of the algorithm in the [paper](http://adsabs.harvard.edu/abs/2006SoPh..236..263M)
 has been already implemented. But it includes additional features like detecting pixels which are on or off limb in a solar map. It is required to implement the python version of the same code only the part demonstrating the calculation of the processed image intensity as shown above.

 Much of this has already implemented by @wafels [here](https://github.com/wafels/sunkit-image/blob/master/sunkit_image/offlimb_enhance.py). The current python code implements both calculating the radial intensity( a summary statistic of the intensity in a map as a function of radius.
) and the intensity distribution in each of the radial bins. Lastly it uses both this functions and calculates the corresponding processed intensity.  The implementation is quite modular, but it still needs to be checked first whether the output is correct by validating against the corresponding IDL output. The python implementation needs to be optimized as much as possible in terms of memory and CPU usage. This can be achieved by eliminating as many as for or while loops possible and replacing them with corresponding numpy functions. Also it should be designed well from an API perspective. Deciding which parameters to the function can be kept default is crucial. Finally before pushing into the sunkit repository, the above code needs to be rigorously tested and well documented.


#### Porting the Multi-Gaussian Algorithm

Extreme ultra-violet images of the corona contain information over a wide range
of spatial scales, and different structures such as active regions, quiet Sun, and filament
channels contain information at very different brightness regimes. So we need to process such images in order to reveal information, often hidden within the data.
MGN Algorithm is thus an efficient process which is based on localized normalizing of the data at many different spatial scales.
The algorithm has been specified in this [paper](https://link.springer.com/content/pdf/10.1007%2Fs11207-014-0523-9.pdf)
The IDL code has already been implemented for the MGN code but some areas of the code are contradictory to the actual algorithm stated in the paper.

Firstly its needed to check whether the IDL code is consistent with the paper.
There has been some cases where the IDL code was found to be inconsistent with the paper.

For example here are a few inconsistencies that I found while comparing the IDL code with the corresponding paper algorithm.

* [First Inconsistency](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369625009)
* [Second Inconsistency](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369627773)


Two python implementations of the MGN algorithm has been mentioned in this [issue](https://github.com/sunpy/sunpy/pull/1899).
One has been implemented by @Cadair (//links) and the other one by @ebuchlin (//links). As a part of this project, we need to check whether any of the two is not consistent with the paper
and additionally check the output image based on an input AIA image data with necessary parameters. After this, we need to check which is more memory efficient and time efficient.
I have already worked on comparing the two implementations by seeing the memory utilization of the two codes and also the time taken by each of them.
The issue where I worked upon is present [here](https://github.com/sunpy/sunkit-image/issues/1).

The output of the two codes proposed by @Cadair and @ebuchlin is applied on `AIA_171_IMAGE`.

@Cadair's implemented code output
![](https://user-images.githubusercontent.com/16035442/36834704-be1db8b0-1d59-11e8-9392-4a9afdc9a767.png)

@ebuchlin's implemented code output
![](https://user-images.githubusercontent.com/16035442/36834676-9fd65ace-1d59-11e8-8f5d-0a2d02d3471f.png)

As it can be seen, the outputs are quite different. So careful investigation needs to be done what are the implementation differences between the two codes.
Also, the IDL code needs to be thoroughly checked for any inconsistencies, some of which I have mentioned [issue 1](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-3696250090), [issue 2](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369627773).


Some of the issues associated with the current implementation in ebuchlin's code are as follows:
- The function does not take user input for the minimum and maximum values of the input image
- Multi-processing is not supported in the current code.
- The code needs to be properly documented along with proper explanation of the algorithm behind the implementation.
- Also the code needs to be thoroughly tested before being ported to the sunkit repository

Also in addition the main MGN function in the code may be broken down to sub-functions like a separate function for performing the convolution.
This will lead to a much better and proper code structure.

Based on the above criteria , the code that's more efficient and provides the correct result will be ported to the sunpy repository.


#### Occult-2 Algorithm Implementation

Coronal loops are immense arches of hot gas on the surface of the Sun, thought to be jets of
hot plasma flowing along in the alleys between the strong coronal magnetic fields. They are visible at X­ray, ultraviolet, and white­light wavelengths, consisting of an arch, extending upward from the
photosphere for tens or hundreds of thousands of kilometers.
Detection of such coronal loops is thus a crucial aspect.
Oriented Coronal Curved Loop Tracing (Occult) Algorithm implements an automated pattern recognition e to extract magnetized loops from images of the solar corona.
A modified version of this algorithm called the OCCULT-2 Algorithm provides a lot more automation due to more number of parameters as opposed to the old version.

The implementation of the OCCULT Algorithm should be such that it takes any fits file like `AIA_171` as input (`input image`)
and returns a high-pass filtered image (`output image`) along with a list of coordinates of the detected coronal loops

The parameters for the function can be taken as follows
-nsm1 = lowpass filter
- nsm2  = highpass filter
-  len0  = minimum length of loop segments
-  nlen = size of moving box [pixels]
-  wid  = half width of loop [pixels]
-  nsig = threshold for starting detection of loop
-  qfill =minimum filling ratio (flux_avg/flux_peak)
-  nmax = maximum number of analyzed structures

The OCCULT Algorithm works in 4 steps

- **Background suppression**

  This step is actually needed for noisy data where we want to suppress any structure detection in the background.
  The paper presents a novel approach of setting the lower intensity values of the image to the median intensity multiplied by a constant factor `qmed`.
  The parts of the image having intensity less than this base value are rendered a constant value. Hence we can suppress the redundant background suppression.
  This can be easily implemented in terms of code, where by in the map data we check for such low intensity values (`zmin`) are set to a constant `k`, where `k` is the product of the median density of the map
  data multiplied by `qmed` , which is chosen accordingly.  The IDL code accordingly does that in its code under `MINIMUM FLUX CORRECTION` [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro)

- **High Pass Filtering and Low Pass Filtering**
  The low pass filter can be used to smooth out the data and remove redundant noise in the data, while the high pass filter enhances the fine structure (in our case - coronal loops structure)
  The IDL version of the code implements the high pass filter mechanism using the `smooth` function in [tracing_auto](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro)
  As an extension to it, I would work on implementing the low pass filter for noise removal in my python code by choosing appropriate value for `nsm1 = nsm2 -2` where `nsm2` is the high pass filter smoothing constant.

- **Loop Structure Tracing**
  This part is the most important part after pre-processing of the map data. Here we wish to find the loop trajectory or the path.
  So we start with the position having the maximum flux intensity and from that point we start tracking the in a bi-directional way by oriented directivity, based on the direction of the ridge with maximum flux.
  This method involves a fundamental step which is the `Tracing Step` which is tracing the coronal loop structure by determining the local ridge direction and the local curvature radius.
  It has been implemented in the IDL code [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_step.pro)


- **Loop Subtraction in Residual Image**

  Once a full loop structure has been traced, we don't want to rescan the former area of the detected loop for the next iteration of the algorithm.
  From an implementation point of view, we can set the former area intensity values to 0 and make a check in order to avoid such areas of already detected loops for further computation.


This is how the output after implementing the OCCULT-2 Algorithm will look like

**Input Image** = TRACE_19980519.fits image file

![](http://www.lmsal.com/~aschwand/software/tracing/trace_image.jpg)


The highpass-filtered IMAGE2 (using a smoothing boxcar of NSM=9 in the highpass filter)

![](http://www.lmsal.com/~aschwand/software/tracing/highpass_filter.jpg)

Finally the list of coordinates of the detected coronal loops being plotted as follows

![](http://www.lmsal.com/~aschwand/software/tracing/traced_loops.jpg)


As part of the project, we need to first cross-check with the IDL version for any inconsistencies with the paper.
The algorithm needs to be implemented with full focus on the approach as stated in the paper. I plan to implement the algorithm by writing
separate functions for background suppression, filtering , loop tracing and the loop subtraction part to provide more clarity to the user. Finally the output needs to be cross-checked
with that of the IDL implementation. Once we get the correct output, we need to focus on improving the memory and time efficiency before porting into the
sunkit-repository. After this, I will work on documenting the relevant portions of the algorithm along with demonstrated examples. In the end the code needs
to be thoroughly tested and hence I would provide such tests for the code.


#### Implementation of Image Resampling

Image Resampling forms one of the important steps in solar image data analysis, including image co-alignment, perspective re-projection of the solar
surface.

The following paper introduces a novel method to perform the image resampling method used in solar images. Considering a nxn 2D image, the algorithm first finds out the Jacobian of the output-plane coordinates and then works on calculating the Jacobian's singular values by working on the singular value decomposition. Finally we filter out the noise from the final filter using both the hanning filter and the gausian filter.

Some initial part including the converting solar image data from one coordinate system to another and finally performing interpolation on the data has been performed in this Pull Request [here](https://github.com/astrofrog/reproject/pull/52)
Much of the implementation of the image resampling has been done in this [Pull Request](https://github.com/astrofrog/reproject/pull/52/files). The current implementation has worked with the interpolation method (bilinear interpolation) as described by the paper.
The current python implementation has only done with the coordinate transformation from one WCS to another WCS. So the image re-sampling algorithm needs to be implemented by calling specific operations like (calculating the Jacobian, calculating it's singular values and finally the filtering part).
The current python code has done with a nice cython implementation (with an aim for faster execution) and has implemented both the hanning filter and gaussian filter.
These functions need to be thoroughly tested first and also checked first against the proposed methodology in the paper for any discrepancy.
Like for example, the  singular value decomposition function and transpose function needs to be thoroughly tested against simple numpy arrays to check for correct working.

Finally we can implement the main image re-sampling algorithm by using specific functions from the cython implementations like (svd for singular value decomposition, map_coordinates for the entire caculation of the Jacobian of the output coordinate and interpolation).
Once the algorithm is set up, it needs to be thoroughly tested against known AIA image plots. Finally the entire code will need to be documented with relevant links to the paper describing the operation being done.

#### Optional extras

As part of the GSOC project, I plan to complete all of the above functionalities within the second phase evaluation as much as possible.
If time permits, I will go for one optional extra work on implementing the **soft morphological filter of solar images**.
This involves implementation of a new image-processing technique that removes noise occuring due to galactic and solar cosmic rays. This implementation can be applied
to SOHO/LASCO coronagraph images.

The idea behind the algorithm is soft-morphological filters,  a branch of non-linear image processing originating from the field of mathematical
morphology, which are particularly effective for noise removal.


## Project Implementation

### Timeline


| Time Period |  My Work Plan  |
|:-------------:|:-------------:|
|May 14 - Jun 11| <li> **First Week** -- Dedicate this time to knowing more about the project and the algorithms(particularly MGN and NRGF) that needs to be implemented as part of the project. Discuss with mentors the modules that need to be imported from the main sunpy repository.</li>  <li>**Second Week** -- Start working on porting the MGN algorithm in the sunkit repository. Having discussed with mentors the potential inconsistencies in the current IDL implementation with the paper, I will work on remove those inconsistencies in the two python codes, available to me. Will dedicate this entire week to work on the two python implementations of MGN, checking for any remaining inconsistencies and validating the output of the two codes against the IDL output.  </li>   <li>**Third Week** After having updated the two python implementations, I plan to make a quick comparison of the memory and CPU utilization of the two codes and based on the results will port the optimized code into the sunkit repository. Document the updated MGN code in terms of all the parameters being used like the `data`, constants like `a0` and `a1` and detail about the kernel  and signal depths. I also plan to give some links to specific portions of the paper corresponding to a particular operation being performed inside the MGN code. </li>  <li>**Fourth Week** - Dedicate the first 2-3 days of the week to adding tests for the updated MGN code. Remaining part of the week will be dedicated to working on the NRGF algorithm. Since @wafels has already implemented a part of the NRGF, it would not take much time to implement the rest of it. Once the function is set up, the output needs to be validated with the corresponding IDL output. Last day of the week will be dedicated to update the documentation of the algorithm with specific links to the paper describing each operation. </li>|
|Jun 11 -Jun15|  **Phase 1 Evaluation** - Any documentation that remains for NRGF will be completed. Add tests for NRGF and will try to complete this within Jun 14th.  |
|Jun 15 - Jul 9| <li> **First Week** Work on removing any potential bugs or issues if any in the implementations of MGN and NRGF. Solve PEP8 issues if any and ensure good code readability. Once the two implementations are all set up and having get them reviewed by mentors, I will get them merged within the first half of the week. Remaining part of the week will be dedicated to studying the OCCULT-2 algorithm from the paper and studying the IDL code side by side.</li> <li> **Second Week** Discuss with mentors for any potential inconsistencies in the IDL code that contradicts with the paper and try to reach to a solution about removing those inconsistencies. Dedicate rest of the week to write the code for OCCULT-2. This would involve working on all the 4 stages of the algorithm as discussed above</li> <li> **Third Week** Work on the implementation of OCCULT-2 and discuss with mentors on potential ways to improve CPU utilization and memory utilization. If approved by mentor I will work on a cython implementation of the code. By the end of the week , I would cross-check with the corresponding IDL output for any inconsistencies, if any.</li> <li>**Fourth Week** First half of the week  will be dedicated to check for any bugs or breaks in the code. Remaining part of the week will be dedicated to updating documentation for the implemented algorithm.  </li>
|Jul 9 - Jul 13|**Phase 2 Evaluation** Plan to work on adding test coverages for the implemented OCCULT-2 algorithm. Any remaining documentation left if any will be completed by this time.|
|Jul 13 - August 6 | <li>**First Week** Start working on the image resampling algorithm. This will start by working on the part being left by rubendv in the pull request. First of all I plan to discuss with mentors potential discrepancies of the current implemented functions with the paper. Resolve any discrepancies and start working on the algorithm. </li> <li>**Second Week**Create a different function under the python implementation which will call appropriate function under the cython implementation and will perform the image resampling method. Test the called functions like `svd`, `hanning filter` and others and check if any error.</li> <li>**Third Week** Once the function is set up, I plan to write tests for the implemented algorithm by updating in the same Pull Request along with detailed documentation. Keep 3-4 days for writing the tests and the remaining days will be devoted to writing the documentation and any remaining work if any. |
|August 6 - 14|**Final Week** - Once the main project has been tidied up, this time will be devoted to working on the optional extra for the soft morphological filter. This will involve comparing the IDL code with the paper implementation for any discrepancies. I will devote much of this week to working on the basic structure for the algorithm. |


I will try my best to complete the entire project 1-2 weeks before the final week. If time provides, I will start working on the follow **post-gsoc** goals

#### Post GSOC Goals

##### Remaining part of Soft-morphological filter.
The remaining part of the algorithm will be implemented during this time, along with detailed documentation and testing.

##### Implementation of NAFE

(Will add more detail to it)
