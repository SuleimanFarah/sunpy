# **Organization: SunPy in OpenAstronomy**

### **Project: Developing SunKit Image**

##### **Mentors: @Cadair, @wafels, @Nabobalis** ** @mbobra**

#### **Student Information**

* Name: Prateek Chanda

* Time Zone : +05:30 GMT

* IRC Handle : prateekiiest

* Github ID: [prateekiiest](https://github.com/prateekiiest)

* Blog - [Prateek Chanda @Med](https://medium.com/@prateekkol21)[ium](https://medium.com/@prateekkol21)

* LinkedIn : [My LinkedIn Profile](https://www.linkedin.com/in/prateek-chanda-iiest/)

* Website : [CodeFolio](https://prateekiiest.github.io/)

* Mail : prateekkol21@gmail.com or prateek.dd2015@cs.iiests.ac.in

* * *


#### **University Information**

*     University: Indian Institute of Engineering Science and Technology, Shibpur

*     Major: Computer Science and Engineering

*     Current Academic Year : Third Year

*     Graduate Year: 2019

* * *


#### **Experience In Programming**

* I have been involved in open source for the past 2 years and been contributing to different open source projects including Algorithms based and Python based Desktop Applications.

* I did two major projects on Machine Learning in Python which majorly uses statistical analysis (pandas, numpy) and the use of Jupyter Notebook. These were project works for Udacity Machine Learning Nanodegree: [Titanic Survival Exploration, ](https://github.com/prateekiiest/titanic_survival_exploration)[Boston Housing.](https://github.com/prateekiiest/boston_housing)

* I worked recently on one of my personal projects based in python which saw many active participation from different communities. The project being called [Code Sleep Python](https://github.com/prateekiiest/Code-Sleep-Python). It is a project based in python for building desktop applications and games in python.

#### **Open Source experience**

* Contributing to Organizations like FOSSASIA and other small organisations: I had been contributing to some open source organizations and repositories for the past two years. I have currently total 163 Pull Requests done so far and 72 issues being worked so far.

* Mentored students under different Open Source events like Hacktoberfest , Kharagpur Winter of Code and 24 Pull Requests on some of my own personal projects primarily written in Python.

* Got the opportunity to speak at different Open Source Summits. Got invited to different developer conferences like RISE Hong Kong 2017, FOSSASIA Open Tech , Google Developers Solve for India among others.

* Currently I am the GitHub Campus Expert of my college and along with direct support from GitHub I am helping to grow my community in campus, involving more people in Open Source and coding.

* * *


#### **Interest In OpenAstronomy**

OpenAstronomy consisting of 8 sub-organisations is a collaboration between open source astronomy and astrophysics projects that are being used by researchers around the world to study our universe. The analysis of data obtained from observatories like SDO , Hubble Space Telescope helps multiple types of research from being able to forecast a solar storm to detect planets in other stars.

Astronomy is at the frontier of science. There are new discoveries made all the time.

I had always a love for the sky and a kind of childhood fascination in the field astronomy and to me its feels amazing to see real time data of the Sun , captured just a few hours back, in my computer screen and I am able to analyse those data obtained. The organisation is inspiring new developers like me to join the open source community and build the project code base together with lead developers and that is where I find the joy of Open Source. It has been really a great experience contributing to Sunpy since I joined the Sunpy community.

I did not qualify for my first GSOC with Open Astronomy back in 2017. But I did not give up. I loved the project and wanted to contribute as much as I can. Having been worked with the SunPy project for the past 1 year, I learnt many new things in open source, team management, writing long lines of code and lastly the joy of your contribution being accepted.

OpenAstronomy along with Google Summer of Code will give me this opportunity to be a part of these huge project work on Solar Data Analysis and I feel it as a privilege to contribute to such an open-source software in the field of astronomy.

### **Contribution to Sunpy**

I have been involved with the SunPy project for the past 1 year contributing since December 2016. And I am delighted to be a part of the latest [version releases](https://zenodo.org/search?page=1&size=20&q=conceptrecid:%22591887%22&sort=-version&all_versions=True) of SunPy and am grateful to being acknowledged for my work.

<table>
  <tr>
    <td>Pull Requests</td>
    <td>Corresponding Issue</td>
    <td>Status</td>
  </tr>
  <tr>
    <td>More Mapcubes Examples - Gallery Examples #2455</td>
    <td>More examples in the gallery on simple map and mapcube manipulation #2413</td>
    <td>Open</td>
  </tr>
  <tr>
    <td>Remove Gamma usage in Map #2424</td>
    <td>Gamma in map doesn't do anything #2333</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Finding Local Peaks in Solar Data - Gallery Update #2339</td>
    <td>Suggested this example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Masking Hot Pixels</td>
    <td>Found Bug in Example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Brightest pixel location may occur at multiple position</td>
    <td>Found similar bug in Example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Brightest pixel location redundancy removed</td>
    <td>Removed Redundancy in Examples</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Added documentation for suds-py3 incompatibility</td>
    <td>VSOClient.query returns no result in Python 3.5</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update README.md Matrix Org linked</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update README.md</td>
    <td>README badges broken</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Added documentation for database/tests</td>
    <td>database tests depend on data/tests dir</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update vso.py</td>
    <td>Enhancement Documentation</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update time.py Removed extract_time</td>
    <td>Remove extract_time function</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update rescale.py</td>
    <td>reshape_image_to_4d_superpixel array seems broken</td>
    <td>Merged</td>
  </tr>
</table>


Contribution to SunPy Website

<table>
  <tr>
    <td>Pull Requests</td>
    <td>Corresponding Issue</td>
    <td>Status</td>
  </tr>
  <tr>
    <td>help section Docs link updated</td>
    <td>Sunpy Documentation Link Showing Privacy Error</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Sunpy Presentations and Talks Upload on the Site</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Registry of Sunpy Affiliated Packages</td>
    <td>Enhancement -Introducing Affiliated Packages Registry</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update bootstrap.css bootstrap version updated</td>
    <td>Update bootstrap</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update about.html Community Link updated to matrix</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
</table>


* * *


### **Abstract**

This project aims at building the foundations of sunkit-image which is a SunPy affiliated package. Through this package SunPy users can analyze solar images collected from different solar data observatories and get a clear picture of image processing applications in the field of solar physics.The package will contain some of the most well-known image processing algorithms structured in a well manner readily usable package. By implementing all such algorithms in a single package will give the user the freedom to analyze solar plots without bothering about the underlying complexity of the implementation.

### **Project Goals**

As part of the project there are major 4 milestones that need to be completed as part of the GSoC project. Also I plan to work on only one optional extra if time permits as per the timeline.

* Implement the normalizing-radial-graded filter (NRGF).

* Porting the Multi-Scale Gaussian Normalisation - MGN code in the sunkit-image repository.

* Implementation of the OCCULT-2 Algorithm for coronal loop tracing.

* Implement image re-sampling

### **Detailed Description**

The project involves four parts along with optional extras. A detailed analysis of each part of the project is described as follows

#### **Implementation of the Normal-Radial-Graded Filter (NRGF)**

The very sharp decrease of density with heliocentric distance makes imaging of coronal density structures out to a few solar radii challenging. The radial gradient in brightness can be reduced using numerous image processing techniques like NRGF. Normalizing radial graded filter (NRGF) is thus a simple filter for removing the radial gradient to reveal coronal structure. It presents a robust normalization technique. The main idea behind this technique can be given by the following equation.

![image alt text](image_0.png)

where the Intensity of the Image is represented in polar coordinates.

What needs to be done

The IDL version of the algorithm in the [paper](http://adsabs.harvard.edu/abs/2006SoPh..236..263M) has been already implemented. But it includes additional features like detecting pixels which are on or off limb in a solar map. It is required to implement the python version of the same code only the part demonstrating the calculation of the processed image intensity as shown above.

Much of this has already implemented by @wafels [here](https://github.com/wafels/sunkit-image/blob/master/sunkit_image/offlimb_enhance.py). The current code implements both calculating the radial intensity (a summary statistic of the intensity in a map as a function of radius) and the intensity distribution in each of the radial bins. Lastly it uses both these functions and calculates the corresponding processed intensity. The implementation is quite modular, but it still needs to be checked first whether the output is correct by validating against the corresponding IDL output. The python implementation needs to be optimized as much as possible in terms of memory and CPU usage. This can be achieved by eliminating too many as for or while loops possible and replacing them with corresponding numpy functions. Also it should be designed well from an API perspective. Deciding which parameters to the function can be kept default is crucial. Finally before merging into the sunkit repository, the above code needs to be rigorously tested and well documented.

#### **Porting the Multi-Gaussian Algorithm**

Many a times we require to process solar images to get hold of hidden information like position of active regions and specific clues with respect to filament channels at different brightness levels. MGN Algorithm is thus an efficient process which is based on localized normalizing of the data at many different spatial scales. The algorithm has been specified in this [paper](https://link.springer.com/content/pdf/10.1007%2Fs11207-014-0523-9.pdf). The IDL code has already been implemented for the MGN code but some areas of the code have contradiction to the actual algorithm stated in the paper.

Firstly its needed to check whether the IDL code is consistent with the paper. There has been some cases where the IDL code was found to be inconsistent with the paper.

For example here are a few inconsistencies that I found while comparing the IDL code with the corresponding paper algorithm.

* [First Inconsistency](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369625009)

* [Second Inconsistency](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369627773)

Two python implementations of the MGN algorithm has been mentioned in this [issue](https://github.com/sunpy/sunpy/pull/1899). One has been implemented by @Cadair [here](https://github.com/sunpy/sunpy/pull/1899/files#diff-ec25d2a41758e53b3ab8c9dca5ab4e96)  and the other one by @ebuchlin [here](https://git.ias.u-psud.fr/ebuchlin/aia-movie/blob/master/medocimage/mgn.py). We need to check the output image based on an input AIA image data with necessary parameters. After this, we need to check which is more memory efficient and time efficient. I have already worked on comparing the two implementations by seeing the memory utilization of the two codes and also the time taken by each of them. The issue where I worked upon is present [here](https://github.com/sunpy/sunkit-image/issues/1).

The output of the two codes proposed by @Cadair and @ebuchlin is shown in this [issue](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369515706). As it can be seen, the outputs are quite different. So careful investigation needs to be done what are the implementation differences between the two codes. Some of the inconsistencies which I found have been mentioned in [issue 1](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-3696250090), [issue 2](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369627773).

Some of the issues associated with the current implementation in ebuchlin's code are as follows:

* The function does not take user input for the minimum and maximum values of the input image

* Multi-processing is not supported in the current code.

* The code needs to be properly documented along with proper explanation of the algorithm behind the implementation.

* Also the code needs to be thoroughly tested before being ported to the sunkit repository

Also in addition the main MGN function in the code may be broken down to sub-functions like a separate function for performing the convolution. This will lead to a much better and proper code structure.

Based on the above criteria , the code that's more efficient and provides the correct result will be ported to the sunpy repository.

#### **Occult-2 Algorithm Implementation**

Detection of such coronal loops is a crucial aspect while analysing solar images since we can derive specific information about the coronal loop structure and also gain some knowledge about coronal heating problem. Oriented Coronal Curved Loop Tracing (Occult) Algorithm implements an automated pattern recognition e to extract magnetized loops from images of the solar corona. A modified version of this algorithm called the OCCULT-2 Algorithm provides a lot more automation due to more number of parameters as opposed to the old version.

The implementation of the OCCULT Algorithm should be such that it takes any fits file like AIA_171 as input (input image) and returns a high-pass filtered image (output image) along with a list of coordinates of the detected coronal loops

The OCCULT Algorithm works in 4 steps

* **Background suppression** - This step is actually needed to deal with noisy data where we want to suppress any structure detection in the background. The paper presents a novel approach of setting the lower intensity values of the image to the median intensity multiplied by a constant factor qmed. The parts of the image having intensity less than this base value are rendered a constant value. This can be easily implemented in terms of code, where by in the map data we check for such low intensity values (zmin) are set to a constant k, where k is the product of the median density of the map data multiplied by qmed. The IDL code accordingly does that in its code under MINIMUM FLUX CORRECTION [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro)

* **High Pass Filtering and Low Pass Filtering** The low pass filter can be used to smooth out the data and remove redundant noise in the data, while the high pass filter enhances the fine structure. The IDL version of the code implements the high pass filter mechanism using the smooth function in [tracing_auto](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro).

* **Loop Structure Tracing** Here we wish to find the loop trajectory or the path. So we start with the position having the maximum flux intensity and from that point we start tracking the in a bi-directional way by oriented directivity, based on the direction of the ridge with maximum flux. It has been implemented in the IDL code [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_step.pro)

* **Loop Subtraction in Residual Image** - Once a full loop structure has been traced, we don't want to rescan the former area of the detected loop for the next iteration of the algorithm. From an implementation point of view, we can set the former area intensity values to 0 and make a check in order to avoid such areas of already detected loops for further computation.

I plan to implement the algorithm by writing separate functions for background suppression, filtering , loop tracing and the loop subtraction part to provide more clarity to the user. Finally the output needs to be cross-checked with that of the IDL implementation. After this, I will work on documenting the relevant portions of the algorithm along with demonstrated examples. In the end the code needs to be thoroughly tested and hence I would provide such tests for the code.

#### **Implementation of Image Resampling**

Image Resampling forms one of the most crucial steps in solar image data analysis, mapping the image from one coordinate system to another.

The following [paper](https://link.springer.com/article/10.1023%2FB%3ASOLA.0000021743.24248.b0) introduces a novel method to perform the image resampling method used in solar images. Considering a nxn 2D image, the algorithm first finds out the Jacobian of the output-plane coordinates and then works on calculating the Jacobian's singular values by working on the singular value decomposition and finally filters out noise through hanning filter and gaussian filter.

Some initial part including the converting solar image data from one coordinate system to another and finally performing interpolation (bilinear interpolation) on the data has been performed in this Pull Request [here](https://github.com/astrofrog/reproject/pull/52). The current code has done with a nice cython implementation (with an aim for faster execution) and has implemented both the hanning filter and gaussian filter. These functions need to be thoroughly tested first and also checked first against the proposed methodology in the paper for any discrepancy. 

Finally we can implement the main image re-sampling algorithm by using (svd for singular value decomposition, map_coordinates for the entire calculation of the Jacobian of the output coordinate and interpolation). Once the algorithm is set up, it needs to be thoroughly tested against known AIA image plots. Finally the entire code will need to be documented with relevant links to the paper describing the operation being done.

## **Project Implementation**

### **Timeline**

<table>
  <tr>
    <td>Time Period</td>
    <td>My Work Plan</td>
  </tr>
  <tr>
    <td>May 14 - Jun 11</td>
    <td>First Week -- Dedicate this time to knowing more about the project and the algorithms(particularly MGN and NRGF) that needs to be implemented as part of the project. Discuss with mentors the modules that need to be imported from the main sunpy repository.
Second Week -- Start working on porting the MGN algorithm in the sunkit repository. Having discussed with mentors the potential inconsistencies in the current IDL implementation with the paper, I will work on merging the two python codes, available to me and finally remove any inconsistency in the final code if any. Will dedicate this entire week to work on the two python implementations of MGN, checking for any remaining inconsistencies and validating the output of the two codes against the IDL output.
Third Week After having updated the two python implementations, I plan to make a quick comparison of the memory and CPU utilization of the two codes and based on the results will port the optimized code into the sunkit repository. Document the updated MGN code in terms of all the parameters being used like the data, constants like a0 and a1 and detail about the kernel and signal depths. I also plan to give some links to specific portions of the paper corresponding to a particular operation being performed inside the MGN code.
Fourth Week - Dedicate the first 2-3 days of the week to adding tests for the updated MGN code. Remaining part of the week will be dedicated to working on the NRGF algorithm. Since @wafels has already implemented a part of the NRGF, it would not take much time to implement the rest of it. Once the function is set up, the output needs to be validated with the corresponding IDL output. Last day of the week will be dedicated to update the documentation of the algorithm with specific links to the paper describing each operation.</td>
  </tr>
  <tr>
    <td>Jun 11 -Jun15</td>
    <td>Phase 1 Evaluation - Any documentation that remains for NRGF will be completed. Add tests for NRGF and will try to complete this within Jun 14th.</td>
  </tr>
  <tr>
    <td>Jun 15 - Jul 9</td>
    <td>First Week Work on removing any potential bugs or issues if any in the implementations of MGN and NRGF. Solve PEP8 issues if any and ensure good code readability. Once the two implementations are all set up and having get them reviewed by mentors, I will get them merged within the first half of the week. Remaining part of the week will be dedicated to studying the OCCULT-2 algorithm from the paper and studying the IDL code side by side.
Second Week Discuss with mentors for any potential inconsistencies in the IDL code that contradicts with the paper and try to reach to a solution about removing those inconsistencies. Dedicate rest of the week to write the code for OCCULT-2. This would involve working on all the 4 stages of the algorithm as discussed above
Third Week Work on the implementation of OCCULT-2 and discuss with mentors on potential ways to improve CPU utilization and memory utilization. If approved by mentor I will work on a cython implementation of the code. By the end of the week , I would cross-check with the corresponding IDL output for any inconsistencies, if any.
Fourth Week First half of the week will be dedicated to check for any bugs or breaks in the code. Remaining part of the week will be dedicated to updating documentation for the implemented algorithm.</td>
  </tr>
  <tr>
    <td>Jul 9 - Jul 13</td>
    <td>Phase 2 Evaluation Plan to work on adding test coverages for the implemented OCCULT-2 algorithm. Any remaining documentation left if any will be completed by this time.</td>
  </tr>
  <tr>
    <td>Jul 13 - August 6</td>
    <td>First Week Start working on the image resampling algorithm. This will start by working on the part being left by rubendv in the pull request. See to it how the implementation matches with the main paper.
Second Week Create a different function under the python implementation which will call appropriate function under the cython implementation and will perform the image resampling method. Test the called functions like svd, hanning filter and others and check if any error.
Third Week Once the function is set up, I plan to write tests for the implemented algorithm by updating in the same Pull Request along with detailed documentation. Keep 3-4 days for writing the tests and the remaining days will be devoted to writing the documentation and any remaining work if any.</td>
  </tr>
  <tr>
    <td>August 6 - 14</td>
    <td>Final Week - Once the main project has been tidied up, this time will be devoted to working on the optional extra for the soft morphological filter. This will involve comparing the IDL code with the paper implementation for any discrepancies. I will devote much of this week to working on the basic structure for the algorithm.</td>
  </tr>
</table>


I will try my best to complete the entire project 1-2 weeks before the final week. If time provides, I will start working on the follow post-gsoc goals

#### **Post GSOC Goals**

##### **Remaining part of Soft-morphological filter.**

The remaining part of the algorithm will be implemented during this time, along with detailed documentation and testing.

##### **Implementation of NAFE**

(Will add more detail to it)

## **GSoC**

### **Have you participated previously in GSoC? When? With which project?**

I have not participated in GSoC before. This is the first time that I would be participating in GSoC.

Are you also applying to other projects?

No. This is the only project and SunPy under OpenAstronomy is the only organization that I have applied for.

* * *


### **Commitment**

* I don’t have any other internships or work for the summer. I don’t have any plans to go on vacation either.

* My classes for the new semester will begin around August 2nd, but I would still be able to give sufficient time for the project as academic load is very less during the initial few weeks of the semester. Hence it will not be much of a problem during the final week. I will be able to spare 35-40 hours for the project per week easily.

* Also, because my summer vacation starts on May 7, I will start working on the project early so that I can try to complete the project well before the deadline ( around 1-2 weeks before the deadline ).

* I have my semester exams from around 22nd of April to 1 May. So I will not be able to contribute much time to the project work during this time. Still I will try to devote 2-3 hours during the weekdays to do my work.

* SunPy is the only organization and this project is the only project that I have applied for.

* * *


## **Eligibility**

Yes, I am eligible to receive payments from Google. For any queries, clarifications or further explanations, feel free to contact me at prateekkol21@gmail.com .

