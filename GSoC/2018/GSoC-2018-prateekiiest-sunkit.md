# Organization: SunPy in OpenAstronomy

### Project: Developing SunKit Image

##### Mentors: @Cadair, @wafels, @Nabobalis  @mbobra

#### **Student Information**

* Name: Prateek Chanda

* Time Zone : +05:30 GMT

* IRC Handle : prateekiiest

* Github ID: [prateekiiest](https://github.com/prateekiiest)

* Blog - [Prateek Chanda @Med](https://medium.com/@prateekkol21)[ium](https://medium.com/@prateekkol21)

* LinkedIn : [My LinkedIn Profile](https://www.linkedin.com/in/prateek-chanda-iiest/)

* Website : [CodeFolio](https://prateekiiest.github.io/)

* Mail : prateekkol21@gmail.com or prateek.dd2015@cs.iiests.ac.in

* * *


#### **University Information**

*  University: Indian Institute of Engineering Science and Technology, Shibpur

*  Major: Computer Science and Engineering

*  Current Academic Year : Third Year

*  Graduate Year: 2019

* * *


#### **Experience In Programming (Projects)**

* I did two major projects on Machine Learning in Python which majorly uses statistical analysis (pandas, numpy) and the use of Jupyter Notebook. These were project works for Udacity Machine Learning Nanodegree: [Titanic Survival Exploration,  ](https://github.com/prateekiiest/titanic_survival_exploration)[Boston Housing.](https://github.com/prateekiiest/boston_housing)

* I worked recently on one of my personal projects based in python which saw many active participation from different communities. The project being called [Code Sleep Python](https://github.com/prateekiiest/Code-Sleep-Python). It is a project based in python for building desktop applications and games in python.

* I also did one research internship during previous summer working on a data mining project using Python - [ Group Activity Recognition](https://github.com/prateekiiest/Student-Group-Activity-Recognition).

* All my independent project works(mostly in Python) can be seen in my [Repositories List](https://github.com/prateekiiest?utf8=%E2%9C%93&tab=repositories&q=&type=source&language=).

#### **Open Source experience**

* Contributing to Organizations like FOSSASIA and other small organisations: I had been contributing to some open source organizations and repositories for the past two years. I have currently total 163 Pull Requests done so far and 72 issues being worked so far.

* Mentored students under different Open Source events like Hacktoberfest , Kharagpur Winter of Code and 24 Pull Requests on some of my own personal projects primarily written in Python.

* Got the opportunity to speak at different Open Source Summits. Got invited to different developer conferences like RISE Hong Kong 2017, FOSSASIA Open Tech , Google Developers Solve for India among others.

* Currently I am the GitHub Campus Expert of my college and along with direct support from GitHub I am helping to grow my community in campus, involving more people in Open Source and coding.

* * *


#### **Interest In OpenAstronomy**

OpenAstronomy consisting of 8 sub-organisations is a collaboration between open source astronomy and astrophysics projects that are being used by researchers around the world to study our universe. The analysis of data obtained from observatories like SDO , Hubble Space Telescope helps multiple types of research from being able to forecast a solar storm or may be detect sunspot locations. I had always been in love with the field astronomy but never really got the opportunity to work in it until I started working on the SunPy project.

I did not qualify for my first GSOC with Open Astronomy back in 2017. But I did not give up. I loved the project and wanted to contribute as much as I can. Having been worked with the SunPy project for the past 1 year, I learnt many new things in open source, team management, contributing patches, and lastly the joy of your contribution being accepted. It has been really a great experience so far contributing to Sunpy.  I feel it as a privilege to be able to contribute to such an open-source software in the field of astronomy.

OpenAstronomy along with Google Summer of Code will thus give me this unique opportunity to be a part of this amazing project.

**Contribution to Sunpy**

I have been involved with the SunPy project for the past 1 year contributing since December 2016. And I am delighted to be a part of the latest [version releases](https://zenodo.org/search?page=1&size=20&q=conceptrecid:%22591887%22&sort=-version&all_versions=True) of SunPy and am grateful to being acknowledged for my work.

<table>
  <tr>
    <td>Pull Requests</td>
    <td>Corresponding Issue</td>
    <td>Status</td>
  </tr>
  <tr>
    <td>More Mapcubes Examples - Gallery Examples #2455</td>
    <td>More examples in the gallery on simple map and mapcube manipulation #2413</td>
    <td>Open</td>
  </tr>
  <tr>
    <td>Remove Gamma usage in Map #2424</td>
    <td>Gamma in map doesn't do anything #2333</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Finding Local Peaks in Solar Data - Gallery Update #2339</td>
    <td>Suggested this example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Masking Hot Pixels</td>
    <td>Found Bug in Example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Brightest pixel location may occur at multiple position</td>
    <td>Found similar bug in Example</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Brightest pixel location redundancy removed</td>
    <td>Removed Redundancy in Examples</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Added documentation for suds-py3 incompatibility</td>
    <td>VSOClient.query returns no result in Python 3.5</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update README.md Matrix Org linked</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update README.md</td>
    <td>README badges broken</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Added documentation for database/tests</td>
    <td>database tests depend on data/tests dir</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update vso.py</td>
    <td>Enhancement Documentation</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update time.py Removed extract_time</td>
    <td>Remove extract_time function</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update rescale.py</td>
    <td>reshape_image_to_4d_superpixel array seems broken</td>
    <td>Merged</td>
  </tr>
</table>


**Contribution to SunPy Website**

<table>
  <tr>
    <td>Pull Requests</td>
    <td>Corresponding Issue</td>
    <td>Status</td>
  </tr>
  <tr>
    <td>help section Docs link updated</td>
    <td>Sunpy Documentation Link Showing Privacy Error</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Sunpy Presentations and Talks Upload on the Site</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Registry of Sunpy Affiliated Packages</td>
    <td>Enhancement -Introducing Affiliated Packages Registry</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update bootstrap.css bootstrap version updated</td>
    <td>Update bootstrap</td>
    <td>Merged</td>
  </tr>
  <tr>
    <td>Update about.html Community Link updated to matrix</td>
    <td>Enhancement</td>
    <td>Merged</td>
  </tr>
</table>


* * *


### **Abstract**

Analysis of solar data collected from different solar observatories is one of the fundamental research area in the heliophysics community. Hence a good processing of such images needs to be done in order to get accurate features and hidden data which can be used for further analysis.

This project aims at building the foundations of **sunkit-image**, a SunPy affiliated package which will contain some well-known image analysis algorithms required for solar data analysis purposes. Through this package SunPy users will be able to analyze solar images and get a clear picture of the image processing techniques in the field of solar physics. By implementing all such algorithms in a single package will give the user convenience and freedom to analyze solar plots without having to bother about the underlying complexity of the algorithm implementations.

### **Project Goals**

As part of the project there are major 4 milestones that need to be completed. If time permits as per my proposed timeline, I would plan to work on the optional extras which I have listed below as part of post-gsoc goals

* Implement the normalizing-radial-graded filter (NRGF) algorithm.

* Porting the Multi-Scale Gaussian Normalisation - MGN code in the sunkit-image repository.

* Implementation of the OCCULT-2 Algorithm for coronal loop tracing.

* Implement image re-sampling algorithm and update it to Astropy project.

### **Detailed Description**

A detailed analysis of each part of the project is described as follows

#### Implementation of the Normal-Radial-Graded Filter (NRGF)

**Motivation**

As we shift outwards from the solar center, we observe a sharp fall in the density with respect to the radial distance from the center. Due to this sharp decrease in density, it becomes quite difficult to observe the coronal density structures. Hence we need an image processing algorithm that can reduce this radial gradient in brightness and produce an image with intricate details of such coronal density structures, easily observable to the end-user.

**How NRGF solves the problem?**

 Normalizing radial graded filter (NRGF) uses a simple filter for removing this radial gradient in the image. Considering at a particular height (radius, r) we get a circular strip of the coronal region. So for r  = 0 (center) to r = R (some radius) we get a number of such circular strips. For each of this strips, we can divide it into small slots each corresponding to the angle measured with respect to the center. For each such slot, we first calculate the mean of the corresponding circular strip intensity, the slot lies in and subtract it from that particular slot intensity. Next we calculate the standard deviation of the intensity of the circular strip and divide the previous difference by it. This way we can reduce much of the steepness in the radial density gradient.

**What my work will include**

The IDL version of the algorithm in the [paper](http://adsabs.harvard.edu/abs/2006SoPh..236..263M) has been already implemented. But it includes additional features like detecting pixels which are on or off limb in a solar map. It is required to implement the python version of the same code only the part demonstrating the calculation of the processed image intensity as shown above. If time provides, we can work on the extra additional features as proposed in the IDL code.

Much of this has already been implemented by @wafels [here](https://github.com/wafels/sunkit-image/blob/master/sunkit_image/offlimb_enhance.py). The current code implements both calculating the radial intensity (a summary statistic of the intensity in a solar map as a function of radius) and the intensity distribution in each of the radial bins. Lastly it uses both these functions and calculates the corresponding processed intensity. The implementation is quite modular, but it still needs to be checked first whether the output is correct by validating against the corresponding IDL output (preferrably a LASCO image). The python implementation needs to be optimized as much as possible in terms of memory and CPU usage. This can be achieved by avoiding loops  as much as possible and replacing them with corresponding numpy functions (like using in a list comprehension). Finally before merging into the sunkit repository, the above code needs to be rigorously tested and well documented in terms of what each function does and about the parameters used.

#### **Porting the Multi-Gaussian Algorithm**

**Motivation**

The coronal image contains relevant information over a wide range of spatial scales including information regarding structures like quiet Sun and active regions. Processing of such image(EUV images or AIA/SDO data) to retrieve hidden patterns and information from the data is crucial and the accuracy of such information depends upon how the noise gets filtered leaving behind only the finest contextual details of the coronal structures. By appropriate processing we can achieve much better features from the data which may be useful in predicting certain patterns in later stage of data analysis.

**How MGN solves the problem**

The proposed algorithm provides an efficient process which normalizes the data locally at different spatial scales. As opposed to common methods like gamma transformation and wavelet transformation these method flattens the noisy regions and reveals the hidden information while preserving the contextual details. The algorithm works by replacing any spurious negative pixel with zero or local mean/median. Considering a Guassian kernel of width w , it obtains the local mean and local standard deviation by performing convolution operations of the kernel with the pixel values of the original image .The image is then normalised by using the local mean and local standard deviation. Finally we take the arctan transformation of the normalised image and after working on the same process for different spatial scales we combine all such normalised components with corresponding weights to form the final image.

**What my work will include**

The algorithm has been specified in this [paper](https://link.springer.com/content/pdf/10.1007%2Fs11207-014-0523-9.pdf). The IDL code has already been implemented for the MGN code but some areas of the code have contradiction to the actual algorithm stated in the paper. Firstly its needed to check whether the IDL code is consistent with the paper. For example here are a few inconsistencies that I found while comparing the IDL code with the corresponding paper algorithm. They are listed in this [thread](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369625009).

Two python implementations of the MGN algorithm has been mentioned in this [issue](https://github.com/sunpy/sunpy/pull/1899). One has been implemented by @Cadair [here](https://github.com/sunpy/sunpy/pull/1899/files#diff-ec25d2a41758e53b3ab8c9dca5ab4e96)  and the other one by @ebuchlin [here](https://git.ias.u-psud.fr/ebuchlin/aia-movie/blob/master/medocimage/mgn.py). The output image based on an input AIA image data with necessary parameters needs to be compared among the two python implementations. After this, we need to check which is more memory efficient and time efficient. I have already worked on comparing the two implementations by seeing the memory utilization of the two codes and also the time taken by each of them. The issue where I worked upon is present [here](https://github.com/sunpy/sunkit-image/issues/1).

The output of the two codes proposed by @Cadair and @ebuchlin is shown in this [issue](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369515706). As it can be seen, the outputs are quite different. So careful investigation needs to be done what are the implementation differences between the two codes and also compare with the paper. Some of the inconsistencies which I found have been mentioned in [issue 1](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-3696250090), [issue 2](https://github.com/sunpy/sunkit-image/issues/1#issuecomment-369627773). Some of the issues associated with the current implementation in ebuchlin's code are listed here.

Also in addition the main MGN function in the code may be broken down to sub-functions to make it more modular. Depending on how the two python codes get modified at the end, we can have a merge of them or keep both in the repository. Finally I plan to work on 1-2 examples on AIA images demonstrating the working of the implemented algorithm.

#### **Occult-2 Algorithm Implementation**

**Motivation**

Detection of coronal loops in solar images (*TRACE, SDO/AIA*) is an important aspect while analysing solar images. We can derive specific information about the coronal loop structure by detecting such loops and also gain knowledge about coronal heating problem. Hence we need a pattern recognition algorithm that can segment the solar image into different regions thereby, extracting such one-dimensional curvi-linear features from the image.

**How the algorithm solves the problem**

The proposed algorithm implements an automated pattern recognition to extract such loops from images. A modified version of this algorithm, the OCCULT-2 Algorithm provides a lot more automation due to only a few control parameters. The implementation of the OCCULT Algorithm should be such that it takes an input image (TRACE or AIA files) and returns a high-pass filtered image along with a list of coordinates of the detected coronal loops. Much of the noise in the original image gets filtered using the high-pass and low-pass filters leaving behind the faint structures below some threshold.

The OCCULT Algorithm works in 4 steps

* **Background suppression** - This step is actually needed to deal with noisy data where we want to suppress any structure detection in the background. The paper presents a novel approach of setting the lower intensity values of the image to the median intensity multiplied by a constant factor qmed. The parts of the image having intensity less than this base value are rendered a constant value. This can be easily implemented in terms of code, where by in the map data we check for such low intensity values (zmin) are set to a constant k, where k is the product of the median density of the map data multiplied by qmed. The IDL code accordingly does that in its code under MINIMUM FLUX CORRECTION [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro)

* **High Pass Filtering and Low Pass Filtering** The low pass filter can be used to smooth out the data and remove redundant noise in the data, while the high pass filter enhances the fine structure. The IDL version of the code implements the high pass filter mechanism using the smooth function in [tracing_auto](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_auto.pro).

* **Loop Structure Tracing** Here we wish to find the loop trajectory or the path. So we start with the position having the maximum flux intensity and from that point we start tracking the in a bi-directional way by oriented directivity, based on the direction of the ridge with maximum flux. It has been implemented in the IDL code [here](https://hesperia.gsfc.nasa.gov/ssw/packages/mjastereo/idl/tracing_step.pro)

* **Loop Subtraction in Residual Image** - Once a full loop structure has been traced, we don't want to rescan the former area of the detected loop for the next iteration of the algorithm. From an implementation point of view, we can set the former area intensity values to 0 and make a check in order to avoid such areas of already detected loops for further computation.

**What my work will include**

I have prepared a rough pseudo-code implementation of OCCULT-W algorithm and have uploaded them in a [gist](https://gist.github.com/prateekiiest/993d1a1cd0a8a25ce8675c56bc534689)
I plan to implement the algorithm in a modular fashion by writing separate functions for background suppression, filtering , loop tracing and the loop subtraction part to provide more clarity to the user. Finally once done, the output needs to be cross-checked with that of the IDL implementation. After this, I will work on documenting the relevant portions of the algorithm along with working on some examples demonstrating the working of the algorithm. In the end the code needs to be thoroughly tested before final porting to the main package.

#### **Implementation of Image Resampling**

**Motivation**

Image Resampling forms one of the most crucial steps in solar image data analysis, mapping the image from one coordinate system to another. Applications include image co-alignment and perspective re-projection of the solar surface. As opposed to ordinary interpolation of data the proposed algorithm performs better under arbitrary transformations.

**How the algorithm solves the problem**

The following [paper](https://link.springer.com/article/10.1023%2FB%3ASOLA.0000021743.24248.b0) "*On Resampling of Solar Images*” introduces a novel method to perform re-sampling of a single pixel under an arbitrary coordinate transformation. Considering a nxn 2D image,the algorithm first calculates the inverse jacobian matrix of the  subroutine Ci( that returns inverse-mapped vector of the input pixel vector). It then works on calculating the Jacobian's singular values by working on the singular value decomposition and finally filters out noise through hanning filter and gaussian filter. There has been several optimization techniques that have been proposed in this paper which I would try to implement if time provides.

**What my work will include**

Some initial part including the coordinate transformation and performing interpolation (bilinear interpolation) on the data has been done in [this Pull Request](https://github.com/astrofrog/reproject/pull/52). The current code has done with a nice cython implementation (with an aim for faster execution) and has implemented both the hanning filter and gaussian filter. These functions need to be thoroughly tested first and also checked first against the proposed methodology in the paper for any discrepancy.

I propose to implement the main image re-sampling algorithm by using (svd for singular value decomposition, map_coordinates for the entire calculation of the Jacobian of the output coordinate and interpolation). Once the algorithm is set up, it needs to be thoroughly tested against known image plots. Finally the entire code will need to be documented describing what each function specifically does.

## **Project Implementation**

### **Timeline**

<table>
  <tr>
    <td>Time Period</td>
    <td>My Work Plan</td>
  </tr>
  <tr>
    <td>May 14 - Jun 11</td>
    <td><li><b>First Week</b> -- Dedicate this time to knowing more about the project and the algorithms(particularly MGN and NRGF) that needs to be implemented as part of the project. Discuss with mentors the modules that need to be imported from the main sunpy repository.</li>
<li><b>Second Week</b> -- Start working on the MGN algorithm in the sunkit repository. Having discussed with mentors the potential inconsistencies in the current IDL implementation with the paper, I will work on merging the two python codes, available to me and finally remove any inconsistency in the final code. Will dedicate this entire week to work on the two python implementations of MGN, checking for any remaining inconsistencies and validating the output of the two codes against the IDL output.</li>
<li><b>Third Week</b> After having updated the two python implementations, I plan to make a quick comparison of the memory and CPU utilization of the two codes and based on the results will port the optimized code into the sunkit repository. Add tests for the updated MGN code.</li>
<li><b>Fourth Week</b> - Dedicate the first 2-3 days of the week to documenting the updated MGN code  in terms of docstrings, all the parameters being used like the data, constants like a0 and a1 and details on signal depths.. Remaining part of the week will be dedicated to working on the NRGF algorithm. Since @wafels has already implemented a part of the NRGF, it would not take much time to implement the rest of it. Once the function is set up, the output needs to be validated with the corresponding IDL output. Last few days of the week will be dedicated to update the documentation of the algorithm.</li></td>
  </tr>
  <tr>
    <td>Jun 11 -Jun15</td>
    <td><b>Phase 1 Evaluation</b> - Any documentation that remains for NRGF will be completed. Add tests for NRGF and will try to complete this within Jun 14th. During this time I will try to complete working on examples describing the working of MGN and NRGF.</td>
  </tr>
  <tr>
    <td>Jun 15 - Jul 9</td>
    <td><li><b>First Week</b> -- Work on removing any potential bugs or issues if any in the implementations of MGN and NRGF. Solve PEP8 issues if any and ensure good code readability. Once the two implementations are all set up and having get them reviewed by mentors, I will get them merged within the first half of the week. Remaining part of the week will be dedicated to studying the OCCULT-2 algorithm from the paper and studying the IDL code side by side.</li>
<li><b>Second Week</b> -- After having discussed further details with mentors regarding its implementation, I plan to dedicate the rest of the week to write code for OCCULT-2. This would involve working on all the 4 stages of the algorithm as discussed above</li>
<li><b>Third Week</b> -- Work on the implementation of OCCULT-2 and try to finish within this week.  If approved by mentor I will work on a cython implementation of the code. By the end of the week , I would cross-check with the corresponding IDL output for any inconsistencies, if any.</li>
<li><b>Fourth Week</b> -- First half of the week will be dedicated to check for any bugs or breaks in the code. Remaining part of the week will be dedicated to updating documentation for the implemented algorithm.</li></td>
  </tr>
  <tr>
    <td>Jul 9 - Jul 13</td>
    <td><b>Phase 2 Evaluation</b> -- Plan to work on adding test coverages for the implemented OCCULT-2 algorithm. Any remaining documentation left if any will be completed by this time.</td>
  </tr>
  <tr>
    <td>Jul 13 - August 6</td>
    <td><li><b>First Week</b> -- Start working on the image resampling algorithm. This will start by working on the part being left in the pull request. See to it how the implementation matches with the main paper.</li>
<li><b>Second Week</b> -- Create a different function which will call appropriate function under the current cython implementation and will perform the image resampling method. Test the called functions like svd, hanning filter and others and check if any error.</li>
<li><b>Third Week</b> -- Once the function is set up, I plan to write tests for the implemented algorithm along with detailed documentation. Keep 3-4 days for writing the tests and the remaining days will be devoted to writing the documentation and updating with an example.</li></td>
  </tr>
  <tr>
    <td>August 6 - 14</td>
    <td><b>Final Week</b> -- Any remaining amount of work like updating the documentation or writing examples for any of the algorithms that could not be completed before will be done during this week. Once the main project has been tidied up, this time will be devoted to working on the optional extra for the soft morphological filter.</td>
  </tr>
</table>


### **Post GSOC Goals**

I would still contribute to this project after GSOC ends. If I can finish the project 1-2 weeks prior to deadline, I would like to implement two optional extras as part of the project. - **Implementation of NAFE **and** Soft Morphological Filter**

### **Software Packages to be used**

* **Sunpy** - modules to be used mainly include sunpy.coordinates and sunpy.map

* **Astropy** - modules like astropy.units , astropy.wcs

* **Scipy** - Some simple image processing modules like gamma transformation

* **Numpy** - Numpy will be used majorly throughout the whole sunkit project

* **Matplotlib** -  will be used for plotting the maps, the original ones and the processed ones.

### How I will successfully complete the project

During the last few months I have been contributing to gallery examples based on SunPy maps and I worked on a Pull Request to find local peaks in the solar map. There I had used image processing tools of scipy and learnt a lot on how we can use such processing tools on solar data to obtain hidden information. Thus I got more interested in the project work. I have also done projects in my university based on image processing and also as a part of course-work had computer graphics course during my previous semester.

I will abide by the time-table as proposed above and will update patch-works regularly. I will be in touch with mentors every week and will update them with my current proceedings and also seek out to them in case of any queries. I will write blog posts based on the three stages of the project (Phase-1, Phase-2 and Final) and will also try to update the posts with relevant works from specific weeks. I will provide clear documentation to each of the algorithms to be implemented so that it can be understood easily by anyone.

I will still be contributing to SunPy after the project ends in August.

## **Benefits to the Community**

By the end of the project, the sunkit image repository will contain the necessary image processing tools, that can be used for processing of solar images collected from different observatories. Since all the current image processing algorithms (MGN. NAFE, Occult-2 and Image Resampling ) are implemented in IDL, conversion to corresponding python code will provide any end-user more convenience. Hence as a separate affiliated package it will give the end-user the freedom to use these modules without having to bother about the underlying algorithm complexities or having to know about IDL. As a future work, we can have examples under the current repository which will depict the usage of the current image processing modules on various types of solar data.

## **GSoC**

**Have you participated previously in GSoC? When? With which project?**

I have not participated in GSoC before. This is the first time that I would be participating in GSoC.

**Are you also applying to other projects?**

SunPy is the only organisation I am applying to and I am applying to another project under SunPy.


* * *


### **Commitment**

* I don’t have any other internships or work for the summer. I don’t have any other plans to go on vacation.

* My classes for the new semester will begin around August 2nd, but I would still be able to give sufficient time for the project as academic load is very less during the initial few weeks of the semester. Hence it will not be much of a problem during the final week. I will be able to spare 30-35 hours for the project per week easily.

* Also, because my summer vacation will be starting on May 3, I will start working on the project early so that I can try to complete the project well before the deadline ( around 1-2 weeks before the deadline ).

* I have my semester exams from around 22nd of April to 1 May. So I will not be able to contribute much time to the project work during this time. Still I will try to devote 2-3 hours during the weekdays to do my work.

* SunPy is the only organization and I am applying for another project under this organisation.


## **Eligibility**

Yes, I am eligible to receive payments from Google. For any queries, clarifications or further explanations, feel free to contact me at prateekkol21@gmail.com .
